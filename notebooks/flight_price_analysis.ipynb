{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78617599",
   "metadata": {},
   "source": [
    "# Google Flights Airfare Forecast - Data Analysis & Model Development\n",
    "\n",
    "This comprehensive notebook explores the Google Flights airfare dataset, performs feature engineering, trains multiple machine learning models, and provides business insights for flight price prediction.\n",
    "\n",
    "## Objectives:\n",
    "1. **Explore and understand** the flight pricing data\n",
    "2. **Engineer meaningful features** for price prediction\n",
    "3. **Train and compare** multiple ML models\n",
    "4. **Analyze model performance** and feature importance\n",
    "5. **Generate business insights** for optimal booking strategies\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a371f56",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for data analysis, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# System and file operations\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"ğŸ“š All libraries imported successfully!\")\n",
    "print(f\"ğŸ Python version: {sys.version}\")\n",
    "print(f\"ğŸ¼ Pandas version: {pd.__version__}\")\n",
    "print(f\"ğŸ“Š NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad0299",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect Data\n",
    "\n",
    "Load the Google Flights airfare dataset and perform initial data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/google_flights_airfare_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"ğŸ“Š Dataset loaded successfully!\")\n",
    "print(f\"ğŸ“ Dataset shape: {df.shape}\")\n",
    "print(f\"ğŸ’¾ Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BASIC DATASET INFORMATION\")\n",
    "print(\"=\"*50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0edbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"ğŸ“‹ First 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nğŸ“‹ Last 5 rows of the dataset:\")\n",
    "display(df.tail())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nğŸ“Š Statistical Summary:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nğŸ” Missing Values:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Missing Percentage': missing_percent.values\n",
    "})\n",
    "display(missing_df[missing_df['Missing Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9810bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values analysis\n",
    "print(\"ğŸ”¢ Unique Values Analysis:\")\n",
    "print(f\"Airlines: {df['airline'].nunique()}\")\n",
    "print(f\"Origins: {df['origin'].nunique()}\")\n",
    "print(f\"Destinations: {df['destination'].nunique()}\")\n",
    "print(f\"Fare Classes: {df['fare_class'].nunique()}\")\n",
    "print(f\"Flight IDs: {df['flight_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nâœˆï¸ Airlines in dataset:\")\n",
    "print(df['airline'].value_counts())\n",
    "\n",
    "print(f\"\\nğŸ« Fare Classes:\")\n",
    "print(df['fare_class'].value_counts())\n",
    "\n",
    "print(f\"\\nğŸ¢ Top 10 Origins:\")\n",
    "print(df['origin'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nğŸ¢ Top 10 Destinations:\")\n",
    "print(df['destination'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db315b",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Clean and prepare the data for analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b677479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Convert datetime columns\n",
    "print(\"ğŸ“… Converting datetime columns...\")\n",
    "df_processed['booking_dt'] = pd.to_datetime(df_processed['booking_dt'])\n",
    "df_processed['departure_dt'] = pd.to_datetime(df_processed['departure_dt'])\n",
    "\n",
    "# Check for invalid dates\n",
    "invalid_dates = df_processed[df_processed['departure_dt'] <= df_processed['booking_dt']]\n",
    "print(f\"âš ï¸ Found {len(invalid_dates)} records with departure date <= booking date\")\n",
    "\n",
    "# Remove invalid records\n",
    "df_processed = df_processed[df_processed['departure_dt'] > df_processed['booking_dt']]\n",
    "print(f\"âœ… After filtering: {len(df_processed)} records remain\")\n",
    "\n",
    "# Check for outliers in price\n",
    "Q1 = df_processed['price'].quantile(0.25)\n",
    "Q3 = df_processed['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df_processed[(df_processed['price'] < lower_bound) | (df_processed['price'] > upper_bound)]\n",
    "print(f\"ğŸ“Š Price outliers detected: {len(outliers)} ({len(outliers)/len(df_processed)*100:.2f}%)\")\n",
    "print(f\"ğŸ“Š Price range: ${df_processed['price'].min():.2f} - ${df_processed['price'].max():.2f}\")\n",
    "print(f\"ğŸ“Š IQR bounds: ${lower_bound:.2f} - ${upper_bound:.2f}\")\n",
    "\n",
    "# Check data quality\n",
    "print(f\"\\nğŸ” Data Quality Check:\")\n",
    "print(f\"Duplicate rows: {df_processed.duplicated().sum()}\")\n",
    "print(f\"Records with price <= 0: {(df_processed['price'] <= 0).sum()}\")\n",
    "print(f\"Records with negative advance days: {((df_processed['departure_dt'] - df_processed['booking_dt']).dt.days < 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be538fb6",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Create meaningful features from the raw data to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f27d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "print(\"ğŸ”§ Creating engineered features...\")\n",
    "\n",
    "# 1. Temporal Features\n",
    "df_processed['days_before_departure'] = (df_processed['departure_dt'] - df_processed['booking_dt']).dt.days\n",
    "\n",
    "# Booking date features\n",
    "df_processed['booking_month'] = df_processed['booking_dt'].dt.month\n",
    "df_processed['booking_day_of_week'] = df_processed['booking_dt'].dt.dayofweek\n",
    "df_processed['booking_day_of_year'] = df_processed['booking_dt'].dt.dayofyear\n",
    "df_processed['booking_hour'] = df_processed['booking_dt'].dt.hour\n",
    "df_processed['booking_quarter'] = df_processed['booking_dt'].dt.quarter\n",
    "\n",
    "# Departure date features\n",
    "df_processed['departure_month'] = df_processed['departure_dt'].dt.month\n",
    "df_processed['departure_day_of_week'] = df_processed['departure_dt'].dt.dayofweek\n",
    "df_processed['departure_hour'] = df_processed['departure_dt'].dt.hour\n",
    "df_processed['departure_quarter'] = df_processed['departure_dt'].dt.quarter\n",
    "\n",
    "# 2. Seasonal Features\n",
    "df_processed['is_weekend_departure'] = df_processed['departure_day_of_week'].isin([5, 6]).astype(int)\n",
    "df_processed['is_weekend_booking'] = df_processed['booking_day_of_week'].isin([5, 6]).astype(int)\n",
    "df_processed['is_summer'] = df_processed['departure_month'].isin([6, 7, 8]).astype(int)\n",
    "df_processed['is_winter_holidays'] = df_processed['departure_month'].isin([12, 1]).astype(int)\n",
    "df_processed['is_spring_break'] = df_processed['departure_month'].isin([3, 4]).astype(int)\n",
    "\n",
    "# 3. Route Features\n",
    "df_processed['route'] = df_processed['origin'] + '_' + df_processed['destination']\n",
    "major_hubs = ['ORD', 'ATL', 'LAX', 'DFW', 'DEN', 'JFK', 'SFO', 'LAS', 'PHX', 'CLT']\n",
    "df_processed['origin_is_hub'] = df_processed['origin'].isin(major_hubs).astype(int)\n",
    "df_processed['destination_is_hub'] = df_processed['destination'].isin(major_hubs).astype(int)\n",
    "\n",
    "# Route popularity\n",
    "route_popularity = df_processed['route'].value_counts() / len(df_processed)\n",
    "df_processed['route_popularity'] = df_processed['route'].map(route_popularity)\n",
    "\n",
    "# 4. Airline Features\n",
    "legacy_carriers = ['American Airlines', 'Delta Air Lines', 'United Airlines']\n",
    "df_processed['is_legacy_carrier'] = df_processed['airline'].isin(legacy_carriers).astype(int)\n",
    "\n",
    "# Airline market share\n",
    "airline_market_share = df_processed['airline'].value_counts() / len(df_processed)\n",
    "df_processed['airline_market_share'] = df_processed['airline'].map(airline_market_share)\n",
    "\n",
    "# 5. Advance Booking Categories\n",
    "df_processed['booking_category'] = pd.cut(\n",
    "    df_processed['days_before_departure'], \n",
    "    bins=[-1, 0, 7, 14, 30, 60, 90, float('inf')],\n",
    "    labels=['same_day', 'week', '2weeks', 'month', '2months', '3months', 'advance']\n",
    ")\n",
    "\n",
    "print(f\"âœ… Feature engineering completed!\")\n",
    "print(f\"ğŸ“Š Total features created: {len(df_processed.columns) - len(df.columns)}\")\n",
    "print(f\"ğŸ“Š Current dataset shape: {df_processed.shape}\")\n",
    "\n",
    "# Display new features summary\n",
    "new_features = [col for col in df_processed.columns if col not in df.columns]\n",
    "print(f\"\\nğŸ†• New features created: {new_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dcee47",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis & Visualization\n",
    "\n",
    "Visualize patterns and relationships in the data to gain insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5685014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Distribution Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Price histogram\n",
    "axes[0, 0].hist(df_processed['price'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].set_title('Price Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Price ($)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Log price distribution\n",
    "axes[0, 1].hist(np.log1p(df_processed['price']), bins=50, alpha=0.7, edgecolor='black', color='orange')\n",
    "axes[0, 1].set_title('Log Price Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Log(Price + 1)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Price by fare class\n",
    "df_processed.boxplot(column='price', by='fare_class', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Price Distribution by Fare Class', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Fare Class')\n",
    "axes[1, 0].set_ylabel('Price ($)')\n",
    "\n",
    "# Price by airline\n",
    "top_airlines = df_processed['airline'].value_counts().head(5).index\n",
    "df_top_airlines = df_processed[df_processed['airline'].isin(top_airlines)]\n",
    "df_top_airlines.boxplot(column='price', by='airline', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Price Distribution by Top Airlines', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Airline')\n",
    "axes[1, 1].set_ylabel('Price ($)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics by key categories\n",
    "print(\"ğŸ“Š Price Statistics by Fare Class:\")\n",
    "print(df_processed.groupby('fare_class')['price'].agg(['count', 'mean', 'median', 'std']).round(2))\n",
    "\n",
    "print(\"\\nğŸ“Š Price Statistics by Top Airlines:\")\n",
    "print(df_processed[df_processed['airline'].isin(top_airlines)].groupby('airline')['price'].agg(['count', 'mean', 'median', 'std']).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad835123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advance Booking Analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Days before departure vs Price\n",
    "sample_data = df_processed.sample(min(10000, len(df_processed)))  # Sample for better visualization\n",
    "axes[0, 0].scatter(sample_data['days_before_departure'], sample_data['price'], alpha=0.5, s=1)\n",
    "axes[0, 0].set_title('Price vs Days Before Departure', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Days Before Departure')\n",
    "axes[0, 0].set_ylabel('Price ($)')\n",
    "\n",
    "# Average price by advance booking category\n",
    "booking_cat_price = df_processed.groupby('booking_category')['price'].mean().reset_index()\n",
    "axes[0, 1].bar(booking_cat_price['booking_category'], booking_cat_price['price'])\n",
    "axes[0, 1].set_title('Average Price by Booking Category', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Booking Category')\n",
    "axes[0, 1].set_ylabel('Average Price ($)')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Price by day of week (departure)\n",
    "dow_price = df_processed.groupby('departure_day_of_week')['price'].mean().reset_index()\n",
    "dow_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[1, 0].bar(range(7), dow_price['price'])\n",
    "axes[1, 0].set_title('Average Price by Departure Day of Week', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Day of Week')\n",
    "axes[1, 0].set_ylabel('Average Price ($)')\n",
    "axes[1, 0].set_xticks(range(7))\n",
    "axes[1, 0].set_xticklabels(dow_labels)\n",
    "\n",
    "# Price by month (departure)\n",
    "month_price = df_processed.groupby('departure_month')['price'].mean().reset_index()\n",
    "axes[1, 1].plot(month_price['departure_month'], month_price['price'], marker='o', linewidth=2, markersize=8)\n",
    "axes[1, 1].set_title('Average Price by Departure Month', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Month')\n",
    "axes[1, 1].set_ylabel('Average Price ($)')\n",
    "axes[1, 1].set_xticks(range(1, 13))\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "correlation_features = ['price', 'days_before_departure', 'booking_month', 'departure_month', \n",
    "                       'booking_day_of_week', 'departure_day_of_week', 'is_weekend_departure',\n",
    "                       'is_legacy_carrier', 'origin_is_hub', 'destination_is_hub', 'route_popularity']\n",
    "\n",
    "correlation_matrix = df_processed[correlation_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ” Key Correlations with Price:\")\n",
    "price_correlations = correlation_matrix['price'].abs().sort_values(ascending=False)\n",
    "for feature, corr in price_correlations.items():\n",
    "    if feature != 'price':\n",
    "        print(f\"   {feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3d52e",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Prepare data for modeling and train multiple machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93cbb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "print(\"ğŸ› ï¸ Preparing data for modeling...\")\n",
    "\n",
    "# Select features for modeling\n",
    "feature_columns = [\n",
    "    'days_before_departure', 'booking_month', 'booking_day_of_week', 'booking_hour', 'booking_quarter',\n",
    "    'departure_month', 'departure_day_of_week', 'departure_hour', 'departure_quarter',\n",
    "    'is_weekend_departure', 'is_weekend_booking', 'is_summer', 'is_winter_holidays', 'is_spring_break',\n",
    "    'origin_is_hub', 'destination_is_hub', 'route_popularity', 'is_legacy_carrier', 'airline_market_share'\n",
    "]\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['airline', 'origin', 'destination', 'fare_class', 'booking_category']\n",
    "le_dict = {}\n",
    "df_model = df_processed.copy()\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in df_model.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_model[f'{col}_encoded'] = le.fit_transform(df_model[col])\n",
    "        le_dict[col] = le\n",
    "        feature_columns.append(f'{col}_encoded')\n",
    "\n",
    "# Prepare features and target\n",
    "X = df_model[feature_columns].fillna(0)\n",
    "y = df_model['price']\n",
    "\n",
    "print(f\"ğŸ“Š Features: {len(feature_columns)}\")\n",
    "print(f\"ğŸ“Š Samples: {len(X)}\")\n",
    "print(f\"ğŸ“Š Feature columns: {feature_columns}\")\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"âœ… Data split completed:\")\n",
    "print(f\"   Training set: {X_train.shape}\")\n",
    "print(f\"   Test set: {X_test.shape}\")\n",
    "\n",
    "# Scale features for linear models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c80502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "print(\"ğŸ¤– Training multiple models...\")\n",
    "\n",
    "models = {\n",
    "    'XGBoost': xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42),\n",
    "    'Ridge Regression': Ridge(alpha=1.0)\n",
    "}\n",
    "\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ”„ Training {name}...\")\n",
    "    \n",
    "    # Use scaled data for Ridge Regression\n",
    "    if name == 'Ridge Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mape': mape,\n",
    "        'cv_mae': -cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'predictions': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"   âœ… {name} completed:\")\n",
    "    print(f\"      MAE: ${mae:.2f}\")\n",
    "    print(f\"      RMSE: ${rmse:.2f}\")\n",
    "    print(f\"      RÂ²: {r2:.4f}\")\n",
    "    print(f\"      MAPE: {mape:.2f}%\")\n",
    "    print(f\"      CV MAE: ${-cv_scores.mean():.2f} (Â±{cv_scores.std():.2f})\")\n",
    "\n",
    "print(\"\\nğŸ† Model Performance Summary:\")\n",
    "print(\"=\"*80)\n",
    "results_df = pd.DataFrame({\n",
    "    name: {\n",
    "        'MAE': f\"${results['mae']:.2f}\",\n",
    "        'RMSE': f\"${results['rmse']:.2f}\",\n",
    "        'RÂ²': f\"{results['r2']:.4f}\",\n",
    "        'MAPE': f\"{results['mape']:.2f}%\",\n",
    "        'CV MAE': f\"${results['cv_mae']:.2f}\"\n",
    "    }\n",
    "    for name, results in model_results.items()\n",
    "}).T\n",
    "\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b1dd29",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "\n",
    "Comprehensive evaluation of trained models with visualizations and feature importance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7588d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Choose best model for detailed analysis\n",
    "best_model_name = min(model_results.keys(), key=lambda x: model_results[x]['mae'])\n",
    "best_model = model_results[best_model_name]\n",
    "print(f\"ğŸ† Best performing model: {best_model_name}\")\n",
    "\n",
    "# 1. Actual vs Predicted scatter plot\n",
    "axes[0, 0].scatter(y_test, best_model['predictions'], alpha=0.5, s=1)\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes[0, 0].set_xlabel('Actual Price ($)')\n",
    "axes[0, 0].set_ylabel('Predicted Price ($)')\n",
    "axes[0, 0].set_title(f'{best_model_name}: Actual vs Predicted', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Residuals plot\n",
    "residuals = y_test - best_model['predictions']\n",
    "axes[0, 1].scatter(best_model['predictions'], residuals, alpha=0.5, s=1)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 1].set_xlabel('Predicted Price ($)')\n",
    "axes[0, 1].set_ylabel('Residuals ($)')\n",
    "axes[0, 1].set_title(f'{best_model_name}: Residuals Plot', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 3. Model comparison (MAE)\n",
    "model_names = list(model_results.keys())\n",
    "mae_values = [model_results[name]['mae'] for name in model_names]\n",
    "axes[1, 0].bar(model_names, mae_values)\n",
    "axes[1, 0].set_title('Model Comparison: Mean Absolute Error', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('MAE ($)')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Model comparison (RÂ²)\n",
    "r2_values = [model_results[name]['r2'] for name in model_names]\n",
    "axes[1, 1].bar(model_names, r2_values)\n",
    "axes[1, 1].set_title('Model Comparison: RÂ² Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('RÂ² Score')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Prediction error analysis\n",
    "print(f\"\\nğŸ“Š Prediction Error Analysis for {best_model_name}:\")\n",
    "print(f\"   Mean residual: ${residuals.mean():.2f}\")\n",
    "print(f\"   Std residual: ${residuals.std():.2f}\")\n",
    "print(f\"   Within $50: {(np.abs(residuals) <= 50).mean()*100:.1f}%\")\n",
    "print(f\"   Within $100: {(np.abs(residuals) <= 100).mean()*100:.1f}%\")\n",
    "print(f\"   Within $200: {(np.abs(residuals) <= 200).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aaeff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "if hasattr(best_model['model'], 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': best_model['model'].feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "    plt.title(f'{best_model_name}: Top 15 Feature Importances', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ğŸ” Top 10 Most Important Features ({best_model_name}):\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):\n",
    "        print(f\"   {i:2d}. {row['feature']}: {row['importance']:.4f}\")\n",
    "else:\n",
    "    print(f\"âš ï¸ {best_model_name} does not provide feature importance\")\n",
    "\n",
    "# Permutation importance for all models\n",
    "print(f\"\\nğŸ” Permutation Importance Analysis:\")\n",
    "for name, results in model_results.items():\n",
    "    if name == best_model_name:  # Only for best model to save time\n",
    "        print(f\"\\n   Calculating permutation importance for {name}...\")\n",
    "        \n",
    "        if name == 'Ridge Regression':\n",
    "            perm_importance = permutation_importance(results['model'], X_test_scaled, y_test, \n",
    "                                                   n_repeats=5, random_state=42, scoring='neg_mean_absolute_error')\n",
    "        else:\n",
    "            perm_importance = permutation_importance(results['model'], X_test, y_test, \n",
    "                                                   n_repeats=5, random_state=42, scoring='neg_mean_absolute_error')\n",
    "        \n",
    "        perm_df = pd.DataFrame({\n",
    "            'feature': feature_columns,\n",
    "            'importance_mean': perm_importance.importances_mean,\n",
    "            'importance_std': perm_importance.importances_std\n",
    "        }).sort_values('importance_mean', ascending=False)\n",
    "        \n",
    "        print(f\"   Top 5 features by permutation importance:\")\n",
    "        for i, (_, row) in enumerate(perm_df.head(5).iterrows(), 1):\n",
    "            print(f\"      {i}. {row['feature']}: {row['importance_mean']:.4f} (Â±{row['importance_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb0a364",
   "metadata": {},
   "source": [
    "## 8. Make Predictions\n",
    "\n",
    "Demonstrate how to use the trained model for new predictions and scenario planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0958d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Predictions\n",
    "print(\"ğŸ”® Making example predictions...\")\n",
    "\n",
    "def create_prediction_features(airline, origin, destination, booking_date, departure_date, fare_class):\n",
    "    \"\"\"Create feature vector for prediction\"\"\"\n",
    "    \n",
    "    # Calculate temporal features\n",
    "    days_before = (departure_date - booking_date).days\n",
    "    \n",
    "    features = {\n",
    "        'days_before_departure': days_before,\n",
    "        'booking_month': booking_date.month,\n",
    "        'booking_day_of_week': booking_date.weekday(),\n",
    "        'booking_hour': booking_date.hour,\n",
    "        'booking_quarter': (booking_date.month - 1) // 3 + 1,\n",
    "        'departure_month': departure_date.month,\n",
    "        'departure_day_of_week': departure_date.weekday(),\n",
    "        'departure_hour': departure_date.hour,\n",
    "        'departure_quarter': (departure_date.month - 1) // 3 + 1,\n",
    "        'is_weekend_departure': 1 if departure_date.weekday() >= 5 else 0,\n",
    "        'is_weekend_booking': 1 if booking_date.weekday() >= 5 else 0,\n",
    "        'is_summer': 1 if departure_date.month in [6, 7, 8] else 0,\n",
    "        'is_winter_holidays': 1 if departure_date.month in [12, 1] else 0,\n",
    "        'is_spring_break': 1 if departure_date.month in [3, 4] else 0,\n",
    "        'origin_is_hub': 1 if origin in major_hubs else 0,\n",
    "        'destination_is_hub': 1 if destination in major_hubs else 0,\n",
    "        'route_popularity': route_popularity.get(f\"{origin}_{destination}\", 0),\n",
    "        'is_legacy_carrier': 1 if airline in legacy_carriers else 0,\n",
    "        'airline_market_share': airline_market_share.get(airline, 0)\n",
    "    }\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    for col in categorical_columns:\n",
    "        if col in le_dict:\n",
    "            if col == 'airline':\n",
    "                features[f'{col}_encoded'] = le_dict[col].transform([airline])[0] if airline in le_dict[col].classes_ else 0\n",
    "            elif col == 'origin':\n",
    "                features[f'{col}_encoded'] = le_dict[col].transform([origin])[0] if origin in le_dict[col].classes_ else 0\n",
    "            elif col == 'destination':\n",
    "                features[f'{col}_encoded'] = le_dict[col].transform([destination])[0] if destination in le_dict[col].classes_ else 0\n",
    "            elif col == 'fare_class':\n",
    "                features[f'{col}_encoded'] = le_dict[col].transform([fare_class])[0] if fare_class in le_dict[col].classes_ else 0\n",
    "            elif col == 'booking_category':\n",
    "                if days_before <= 0:\n",
    "                    cat = 'same_day'\n",
    "                elif days_before <= 7:\n",
    "                    cat = 'week'\n",
    "                elif days_before <= 14:\n",
    "                    cat = '2weeks'\n",
    "                elif days_before <= 30:\n",
    "                    cat = 'month'\n",
    "                elif days_before <= 60:\n",
    "                    cat = '2months'\n",
    "                elif days_before <= 90:\n",
    "                    cat = '3months'\n",
    "                else:\n",
    "                    cat = 'advance'\n",
    "                features[f'{col}_encoded'] = le_dict[col].transform([cat])[0] if cat in le_dict[col].classes_ else 0\n",
    "    \n",
    "    return [features.get(col, 0) for col in feature_columns]\n",
    "\n",
    "# Example scenarios\n",
    "scenarios = [\n",
    "    {\n",
    "        'name': 'Early Bird Business Trip',\n",
    "        'airline': 'American Airlines',\n",
    "        'origin': 'ORD',\n",
    "        'destination': 'BOS',\n",
    "        'booking_date': datetime(2024, 1, 15, 10, 0),\n",
    "        'departure_date': datetime(2024, 3, 15, 8, 0),\n",
    "        'fare_class': 'Economy'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Last Minute Weekend Trip',\n",
    "        'airline': 'American Airlines',\n",
    "        'origin': 'ORD',\n",
    "        'destination': 'BOS',\n",
    "        'booking_date': datetime(2024, 6, 20, 15, 0),\n",
    "        'departure_date': datetime(2024, 6, 22, 18, 0),\n",
    "        'fare_class': 'Economy'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Summer Vacation - Business Class',\n",
    "        'airline': 'American Airlines',\n",
    "        'origin': 'ORD',\n",
    "        'destination': 'BOS',\n",
    "        'booking_date': datetime(2024, 4, 1, 12, 0),\n",
    "        'departure_date': datetime(2024, 7, 15, 14, 0),\n",
    "        'fare_class': 'Business'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ¯ Prediction Examples:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for scenario in scenarios:\n",
    "    features = create_prediction_features(**scenario)\n",
    "    features_array = np.array(features).reshape(1, -1)\n",
    "    \n",
    "    predicted_price = best_model['model'].predict(features_array)[0]\n",
    "    \n",
    "    print(f\"\\nâœˆï¸ {scenario['name']}:\")\n",
    "    print(f\"   Route: {scenario['origin']} â†’ {scenario['destination']}\")\n",
    "    print(f\"   Airline: {scenario['airline']}\")\n",
    "    print(f\"   Fare Class: {scenario['fare_class']}\")\n",
    "    print(f\"   Booking Date: {scenario['booking_date'].strftime('%Y-%m-%d %H:%M')}\")\n",
    "    print(f\"   Departure Date: {scenario['departure_date'].strftime('%Y-%m-%d %H:%M')}\")\n",
    "    print(f\"   Days in Advance: {(scenario['departure_date'] - scenario['booking_date']).days}\")\n",
    "    print(f\"   ğŸ’° Predicted Price: ${predicted_price:.2f}\")\n",
    "\n",
    "print(f\"\\nğŸ”® All predictions made using: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff8b43",
   "metadata": {},
   "source": [
    "## 9. Business Insights & Recommendations\n",
    "\n",
    "Key findings and actionable recommendations for travelers and business applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a028396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Insights Analysis\n",
    "print(\"ğŸ’¼ BUSINESS INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Advance Booking Analysis\n",
    "advance_booking_analysis = df_processed.groupby('booking_category')['price'].agg(['mean', 'median', 'count']).round(2)\n",
    "print(\"\\nğŸ“… Advance Booking Strategy:\")\n",
    "print(advance_booking_analysis)\n",
    "\n",
    "optimal_booking = advance_booking_analysis['mean'].idxmin()\n",
    "savings_potential = advance_booking_analysis['mean'].max() - advance_booking_analysis['mean'].min()\n",
    "print(f\"\\nğŸ¯ Optimal booking window: {optimal_booking}\")\n",
    "print(f\"ğŸ’° Potential savings: ${savings_potential:.2f}\")\n",
    "\n",
    "# 2. Day of Week Analysis\n",
    "dow_analysis = df_processed.groupby('departure_day_of_week')['price'].agg(['mean', 'count']).round(2)\n",
    "dow_labels = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_analysis.index = dow_labels\n",
    "print(f\"\\nğŸ“† Day of Week Analysis:\")\n",
    "print(dow_analysis)\n",
    "\n",
    "cheapest_day = dow_analysis['mean'].idxmin()\n",
    "most_expensive_day = dow_analysis['mean'].idxmax()\n",
    "dow_savings = dow_analysis['mean'].max() - dow_analysis['mean'].min()\n",
    "print(f\"\\nğŸ¯ Cheapest departure day: {cheapest_day}\")\n",
    "print(f\"ğŸ¯ Most expensive day: {most_expensive_day}\")\n",
    "print(f\"ğŸ’° Potential savings: ${dow_savings:.2f}\")\n",
    "\n",
    "# 3. Seasonal Analysis\n",
    "seasonal_analysis = df_processed.groupby('departure_month')['price'].agg(['mean', 'count']).round(2)\n",
    "print(f\"\\nğŸŒ Seasonal Price Analysis:\")\n",
    "print(seasonal_analysis)\n",
    "\n",
    "cheapest_month = seasonal_analysis['mean'].idxmin()\n",
    "most_expensive_month = seasonal_analysis['mean'].idxmax()\n",
    "seasonal_savings = seasonal_analysis['mean'].max() - seasonal_analysis['mean'].min()\n",
    "print(f\"\\nğŸ¯ Cheapest month: {cheapest_month}\")\n",
    "print(f\"ğŸ¯ Most expensive month: {most_expensive_month}\")\n",
    "print(f\"ğŸ’° Seasonal savings potential: ${seasonal_savings:.2f}\")\n",
    "\n",
    "# 4. Airline Analysis\n",
    "airline_analysis = df_processed.groupby('airline')['price'].agg(['mean', 'median', 'count']).round(2)\n",
    "print(f\"\\nâœˆï¸ Airline Price Comparison:\")\n",
    "print(airline_analysis.sort_values('mean'))\n",
    "\n",
    "# 5. Route Analysis\n",
    "top_routes = df_processed['route'].value_counts().head(10)\n",
    "route_price_analysis = df_processed[df_processed['route'].isin(top_routes.index)].groupby('route')['price'].agg(['mean', 'count']).round(2)\n",
    "print(f\"\\nğŸ›£ï¸ Top Routes Price Analysis:\")\n",
    "print(route_price_analysis.sort_values('mean'))\n",
    "\n",
    "# Key Business Recommendations\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¯ KEY BUSINESS RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "recommendations = [\n",
    "    f\"ğŸ“… Book flights in the '{optimal_booking}' window for maximum savings (avg ${savings_potential:.0f} less)\",\n",
    "    f\"ğŸ“† Fly on {cheapest_day}s instead of {most_expensive_day}s to save up to ${dow_savings:.0f}\",\n",
    "    f\"ğŸŒ Travel in month {cheapest_month} instead of month {most_expensive_month} for ${seasonal_savings:.0f} savings\",\n",
    "    f\"ğŸ« Business class tickets show different patterns - analyze separately for corporate travel\",\n",
    "    f\"ğŸ¢ Hub airports (ORD, ATL, etc.) often have more competitive pricing\",\n",
    "    f\"â° Weekend departures typically cost more - plan weekday travel when possible\",\n",
    "    f\"ğŸ”„ Use the API's scenario planning feature to compare multiple booking dates\",\n",
    "    f\"ğŸ“Š Monitor price trends 30-60 days before departure for optimal booking timing\"\n",
    "]\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i:2d}. {rec}\")\n",
    "\n",
    "# Model Performance Summary\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¤– MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ† Best Model: {best_model_name}\")\n",
    "print(f\"ğŸ“Š Mean Absolute Error: ${best_model['mae']:.2f}\")\n",
    "print(f\"ğŸ“Š RÂ² Score: {best_model['r2']:.4f}\")\n",
    "print(f\"ğŸ“Š MAPE: {best_model['mape']:.2f}%\")\n",
    "print(f\"âœ… The model can predict flight prices within ${best_model['mae']:.0f} on average\")\n",
    "\n",
    "# Implementation Notes\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ IMPLEMENTATION NOTES\")\n",
    "print(\"=\"*60)\n",
    "implementation_notes = [\n",
    "    \"The trained model has been saved and can be deployed via the FastAPI\",\n",
    "    \"Real-time predictions available through POST /predict endpoint\",\n",
    "    \"Scenario planning available through POST /scenario-planning endpoint\",\n",
    "    \"Model should be retrained periodically with new data\",\n",
    "    \"Consider ensemble methods for improved accuracy\",\n",
    "    \"Monitor model drift and performance in production\",\n",
    "    \"Implement A/B testing for different model versions\"\n",
    "]\n",
    "\n",
    "for i, note in enumerate(implementation_notes, 1):\n",
    "    print(f\"{i}. {note}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Analysis Complete! The ML system is ready for deployment.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
